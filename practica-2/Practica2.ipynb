{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcSTP9oRmSRA"
   },
   "source": [
    "# Practica 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_E2tBqzPmSRG",
    "outputId": "71b14ac2-7c5d-4a18-f96f-c819b9326b99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sjkdm/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbbF5OdMmSRR"
   },
   "outputs": [],
   "source": [
    "with open('corpusML.txt', 'r') as f:\n",
    "    corpus = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9W5gl73mSRZ"
   },
   "outputs": [],
   "source": [
    "corpus = [unidecode(line.lower()) for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qUoSDWzCmSRh",
    "outputId": "5c2d008e-7279-40f8-d434-a3888121fdc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comence a trabajar y me pegaron, me maltrataron con chicote \\n',\n",
       " 'mis patrones me pegaron porque no me queria apurar, porque era flojo \\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6lA3b_ImSRr"
   },
   "source": [
    "### 1, 2) Limpiar corpus y agregar simbolos de inicio y fin\n",
    "\n",
    "* Se limpia el corpus mediante el algoritmo de Porter para el lenguaje español. \n",
    "* A cada oracion del corpus, se le agrega el simbolo de inicio y fin. \n",
    "* Se crea el alfabeto $\\Sigma$ del corpus donde se almacenen unicamente los tipos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kqmg26AGmSRt"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "stems = []                                              # Lista de stems por cada oracion\n",
    "cleanedCorpus = []                                      # Corpus procesado con stemming\n",
    "Sigma = []                                              # Alfabeto del corpus (tipos)               \n",
    "\n",
    "for sentence in corpus:\n",
    "    tokens = nltk.word_tokenize(sentence)               # Obtener lista tokens\n",
    "    for tk in tokens:   \n",
    "        if tk.isalpha():                                # Validar token como caracter del alfabeto                                \n",
    "            stem = stemmer.stem(tk)                     # Aplicar algotimo de stemming\n",
    "            stems.append(stem)                          \n",
    "            if stem not in Sigma:                      \n",
    "                Sigma.append(stem)\n",
    "    s = '<BOS> ' + ' '.join(stems) + ' <EOS>'           # Agregar simbolos de inicio y fin\n",
    "    cleanedCorpus.append(s)                             # Agregar oracion procesada a la lista del corpus limpio                               \n",
    "    stems.clear()\n",
    "\n",
    "# Agregar simbolos de inicio y fin al alfabeto\n",
    "Sigma.append('<BOS>')\n",
    "Sigma.append('<EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Nl9p4iTemSRy",
    "outputId": "a03bdc6c-3798-4058-914b-541a92189e5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<BOS> comenc a trabaj y me peg me maltrat con chicot <EOS>',\n",
       " '<BOS> mis patron me peg porqu no me queri apur porqu era floj <EOS>',\n",
       " '<BOS> por eso me habi peg <EOS>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedCorpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "f-wuyNUVmSR6",
    "outputId": "b7687372-a7ad-4cd5-dd4c-f8285a24055e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab',\n",
       " 'bebecit',\n",
       " 'tabiqu',\n",
       " 'calent',\n",
       " 'pajuel',\n",
       " 'vapor',\n",
       " 'quemart',\n",
       " 'cai',\n",
       " '<BOS>',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP_A9dbrmSSF"
   },
   "source": [
    "### 3) Obtener los bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQT-0gNhmSSK"
   },
   "outputs": [],
   "source": [
    "def bigrams(sequence):\n",
    "    s = sequence.split()\n",
    "    return [(wi, wj) for wi, wj in zip(s[:-1], s[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmYaP-pSmSSZ"
   },
   "outputs": [],
   "source": [
    "# Obtener los bigramas del corpus limpio\n",
    "sentence_bigrams = [bigrams(s) for s in cleanedCorpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "jUPuGfnzmSSg",
    "outputId": "94761f5c-b7c0-4d1c-afd1-7b745c6a1f1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BOS>', 'comenc'),\n",
       " ('comenc', 'a'),\n",
       " ('a', 'trabaj'),\n",
       " ('trabaj', 'y'),\n",
       " ('y', 'me'),\n",
       " ('me', 'peg'),\n",
       " ('peg', 'me'),\n",
       " ('me', 'maltrat'),\n",
       " ('maltrat', 'con'),\n",
       " ('con', 'chicot'),\n",
       " ('chicot', '<EOS>')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bigrams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZoT7VkCmSSo"
   },
   "outputs": [],
   "source": [
    "# Bigramas de todo el corpus\n",
    "corpus_bigrams = [bigram for sentence in sentence_bigrams for bigram in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myOHGiPxmSS7"
   },
   "outputs": [],
   "source": [
    "# Obtener los vectores one hot de cada palabra en el corpus\n",
    "oneHotMatrix = np.identity(len(Sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNmrEckumSTA"
   },
   "outputs": [],
   "source": [
    "word2oneHot = {}        # Entrada: palabra del alfabeto, Salida: vector one hot\n",
    "word2number = {}        # Entrada: palabra del alfabeto, Salida: indice en la lista del alfabeto\n",
    "oneHot2word = {}        # Entrada: vector one hot (caracteres), Salida: palabra del alfabeto\n",
    "\n",
    "for i, (word, vector) in enumerate(zip(Sigma, oneHotMatrix)):\n",
    "    word2oneHot[word] = vector\n",
    "    word2number[word] = i\n",
    "    oneHot2word[np.where(vector==1)[0][0]] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "G6er5MpFmSTH",
    "outputId": "033bea6b-5e86-4775-dbdf-1375c8c1b96d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2oneHot['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JUecUaCjmSTP",
    "outputId": "edb65d70-7d29-4dfa-e1af-c2bab3386856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1215"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2number['<EOS>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "coOlu5LImSTc"
   },
   "source": [
    "### 4) Entrenar la red neuronal con los bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WE8kqhBhmSTh"
   },
   "source": [
    "Dados los bigramas del corpus $(w_i, w_j)$, la red neuronal word2vec es entrenada tomando como entrada y salida a la representacion vectorial *one hot encoded* de la palabra $w_i$ y la palabra $w_j$ respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2es5ygiEEDl"
   },
   "outputs": [],
   "source": [
    "class word2vec():\n",
    "    def __init__(self, d, N, weights):\n",
    "        if weights:\n",
    "            self.U = weights[0]\n",
    "            self.W = weights[1]\n",
    "        else:\n",
    "            self.U = np.random.randn(d, N)*np.sqrt(1/(d+N)) \n",
    "            self.W = np.random.randn(N, d)*np.sqrt(1/(d+N)) \n",
    "            \n",
    "    def softmax(self, x):\n",
    "        exp = np.exp(x-np.max(x))\n",
    "        return np.divide(exp, np.sum(exp))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        h = np.dot(self.U, x)\n",
    "        a = np.dot(self.W, h)\n",
    "        return self.softmax(a)\n",
    "    \n",
    "    def fit(self, bigrams, lr, epochs):\n",
    "        lossWi = []\n",
    "        loss = []\n",
    "        for epoch in range(epochs):\n",
    "            for k, (wi, wj) in enumerate(bigrams):\n",
    "                x = word2oneHot[wi]\n",
    "                y = word2oneHot[wj]\n",
    "                # Feedforward\n",
    "                h = self.U[:, np.where(x==1)[0][0]]\n",
    "                a = self.softmax(np.dot(self.W, h))\n",
    "                # Calcular error\n",
    "                error = a - y\n",
    "                # ---- Calcular funcion de perdida ----\n",
    "                lossWi.append(np.log(a[np.where(y==1)[0][0]]+0.0000000000001))\n",
    "                if k == len(bigrams)-1:\n",
    "                    loss.append(-np.sum(lossWi))\n",
    "                    lossWi.clear()\n",
    "                    print('EPOCH ({}) = {}'.format(epoch+1, loss[epoch]))\n",
    "                # -------------------------------------\n",
    "                # Backpropragation\n",
    "                dW = np.outer(error, h)\n",
    "                self.W -= lr*dW\n",
    "                dU = np.dot(self.W.T, error)\n",
    "                self.U[:, np.where(x==1)[0][0]] -= lr*dU\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXk5_YfhGypu"
   },
   "outputs": [],
   "source": [
    "w2v = word2vec(300, len(Sigma), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 15387
    },
    "colab_type": "code",
    "id": "V87h_2UmHDFF",
    "outputId": "678a9893-f790-4653-cf7c-676b36877e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH (1) = 88540.04035694257\n",
      "EPOCH (2) = 87563.2395231307\n",
      "EPOCH (3) = 85111.47455143604\n",
      "EPOCH (4) = 83063.44945773488\n",
      "EPOCH (5) = 80943.28931752767\n",
      "EPOCH (6) = 78631.31894757965\n",
      "EPOCH (7) = 76164.09006487996\n",
      "EPOCH (8) = 73772.8260329155\n",
      "EPOCH (9) = 71637.66750051823\n",
      "EPOCH (10) = 69803.9779112821\n",
      "EPOCH (11) = 68252.69795043182\n",
      "EPOCH (12) = 66891.89634484766\n",
      "EPOCH (13) = 65674.03854017355\n",
      "EPOCH (14) = 64569.41958924678\n",
      "EPOCH (15) = 63552.084920478475\n",
      "EPOCH (16) = 62610.031046847726\n",
      "EPOCH (17) = 61738.07517302538\n",
      "EPOCH (18) = 60933.52796945114\n",
      "EPOCH (19) = 60194.06805261693\n",
      "EPOCH (20) = 59517.35653043348\n",
      "EPOCH (21) = 58897.53361616776\n",
      "EPOCH (22) = 58326.577365012505\n",
      "EPOCH (23) = 57797.81488775553\n",
      "EPOCH (24) = 57305.30139870303\n",
      "EPOCH (25) = 56843.27896565282\n",
      "EPOCH (26) = 56406.647550456546\n",
      "EPOCH (27) = 55991.20453314094\n",
      "EPOCH (28) = 55593.6766307463\n",
      "EPOCH (29) = 55211.64263495792\n",
      "EPOCH (30) = 54843.365883700906\n",
      "EPOCH (31) = 54487.65610773818\n",
      "EPOCH (32) = 54143.776215006605\n",
      "EPOCH (33) = 53811.313960870255\n",
      "EPOCH (34) = 53489.97547765213\n",
      "EPOCH (35) = 53179.35810198969\n",
      "EPOCH (36) = 52878.82094985356\n",
      "EPOCH (37) = 52587.5174901899\n",
      "EPOCH (38) = 52304.53334116371\n",
      "EPOCH (39) = 52029.02320627947\n",
      "EPOCH (40) = 51760.28907296286\n",
      "EPOCH (41) = 51497.80053655485\n",
      "EPOCH (42) = 51241.18145516407\n",
      "EPOCH (43) = 50990.18582323433\n",
      "EPOCH (44) = 50744.67377979259\n",
      "EPOCH (45) = 50504.583840244115\n",
      "EPOCH (46) = 50269.88941602821\n",
      "EPOCH (47) = 50040.53777932969\n",
      "EPOCH (48) = 49816.39544807602\n",
      "EPOCH (49) = 49597.23465674234\n",
      "EPOCH (50) = 49382.7673894782\n",
      "EPOCH (51) = 49172.697669646215\n",
      "EPOCH (52) = 48966.760474445335\n",
      "EPOCH (53) = 48764.73717290708\n",
      "EPOCH (54) = 48566.453833601874\n",
      "EPOCH (55) = 48371.77227180533\n",
      "EPOCH (56) = 48180.580706612614\n",
      "EPOCH (57) = 47992.787094522486\n",
      "EPOCH (58) = 47808.31566832129\n",
      "EPOCH (59) = 47627.10599708699\n",
      "EPOCH (60) = 47449.113374297915\n",
      "EPOCH (61) = 47274.30904557686\n",
      "EPOCH (62) = 47102.67867498885\n",
      "EPOCH (63) = 46934.21780692076\n",
      "EPOCH (64) = 46768.92421497198\n",
      "EPOCH (65) = 46606.78886580863\n",
      "EPOCH (66) = 46447.78881725925\n",
      "EPOCH (67) = 46291.88515642614\n",
      "EPOCH (68) = 46139.02657599756\n",
      "EPOCH (69) = 45989.15617418301\n",
      "EPOCH (70) = 45842.21794699738\n",
      "EPOCH (71) = 45698.160621999355\n",
      "EPOCH (72) = 45556.93843479433\n",
      "EPOCH (73) = 45418.50975369147\n",
      "EPOCH (74) = 45282.83480752645\n",
      "EPOCH (75) = 45149.873520169975\n",
      "EPOCH (76) = 45019.583997973554\n",
      "EPOCH (77) = 44891.92179890958\n",
      "EPOCH (78) = 44766.83985302763\n",
      "EPOCH (79) = 44644.288820171656\n",
      "EPOCH (80) = 44524.217702515656\n",
      "EPOCH (81) = 44406.57459193371\n",
      "EPOCH (82) = 44291.3074705213\n",
      "EPOCH (83) = 44178.36498820862\n",
      "EPOCH (84) = 44067.697134488\n",
      "EPOCH (85) = 43959.25572493538\n",
      "EPOCH (86) = 43852.99464924556\n",
      "EPOCH (87) = 43748.869874551296\n",
      "EPOCH (88) = 43646.83925465162\n",
      "EPOCH (89) = 43546.86224525819\n",
      "EPOCH (90) = 43448.899649210616\n",
      "EPOCH (91) = 43352.91350181492\n",
      "EPOCH (92) = 43258.867156829365\n",
      "EPOCH (93) = 43166.725565592766\n",
      "EPOCH (94) = 43076.45568096746\n",
      "EPOCH (95) = 42988.02688495279\n",
      "EPOCH (96) = 42901.41134044898\n",
      "EPOCH (97) = 42816.5841956744\n",
      "EPOCH (98) = 42733.523609211945\n",
      "EPOCH (99) = 42652.210601287225\n",
      "EPOCH (100) = 42572.62876537041\n",
      "CPU times: user 1h 59min 32s, sys: 26min 7s, total: 2h 25min 40s\n",
      "Wall time: 1h 12min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "err = w2v.fit(corpus_bigrams, 0.004, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2W8oRYEmSUK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0e54b3031105>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Guardar parametros de la red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'err' is not defined"
     ]
    }
   ],
   "source": [
    "# Guardar parametros de la red\n",
    "with open('weights.pickle', 'wb') as file:\n",
    "    pickle.dump([w2v.U, w2v.W, err], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wgiy2gWJmSUQ"
   },
   "outputs": [],
   "source": [
    "# Leer el archivo con los parametros\n",
    "# y verificar que sean correctos\n",
    "with open('weights.pickle', 'rb') as file:\n",
    "    U, W, err = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "qASSqgWgmSUd",
    "outputId": "3ad4e242-ce5a-448a-d0ce-e0bb990a473c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma =  1.0000000000000002\n",
      "Indice palabra pred =  148\n",
      "Prediccion =  dos\n",
      "P(dos|las) = 0.06175388656226358\n",
      "las dos\n"
     ]
    }
   ],
   "source": [
    "# Prueba de prediccion\n",
    "word = 'las'\n",
    "wordVector = word2oneHot[stemmer.stem(word)]\n",
    "pred = predict(wordVector)\n",
    "print('Suma = ', np.sum(pred))                    # Suma para verificar que sea igual a 1\n",
    "indice = np.argmax(pred)                          # Indice de la palabra con mayor probilidad\n",
    "word_predicted = oneHot2word[indice] \n",
    "\n",
    "print('Indice palabra pred = ', indice)\n",
    "print('Prediccion = ', word_predicted)\n",
    "print('P({}|{}) = {}'.format(word_predicted, word, pred[indice]))\n",
    "print(word + ' ' + word_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWnA8xBamSUm",
    "outputId": "b04c115f-8d03-474c-8cbc-00143d89291a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1b40f9574a05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'err' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAEzCAYAAAAGisbbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAD6pJREFUeJzt3V+I5Xd5x/HPY2IqaGqh2YJkkybQtTYNQuwQLF5o0ZYkF5sbWxKQ1hLcm0ZpFSGi2BKvqhRBiLZbKqmCpmkv2qVsyUWb0lIayYptaCKBJW3NECGrxtwEjWmfXsxUxslk57freWb3JK8XLMzvnO+ceeDLTN75/c6f6u4AADDjVRd6AACAlzOxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMGjf2Kqqz1fV01X1Hy9xf1XVZ6rqdFU9UlVvWf2YAADracmZrXuT3HSW+29OcmT737Ekn/vxxwIAeHnYN7a6+5+SfOcsS25N8oXe8lCSn6qqN6xqQACAdbaK52xdmeTJHceb27cBALziXbqCx6g9btvzM4Cq6li2LjXmta997S+96U1vWsGPBwCY9dWvfvVb3X3ofL53FbG1meSqHceHkzy118LuPp7keJJsbGz0qVOnVvDjAQBmVdV/n+/3ruIy4okkv7n9qsS3Jnm2u7+5gscFAFh7+57ZqqovJ3lHkiuqajPJ7yd5dZJ09x8nOZnkliSnkzyX5LenhgUAWDf7xlZ3377P/Z3kd1Y2EQDAy4h3kAcAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAYtiq2quqmqHq+q01V11x73X11VD1bV16rqkaq6ZfWjAgCsn31jq6ouSXJPkpuTXJfk9qq6bteyjyW5v7tvSHJbks+uelAAgHW05MzWjUlOd/cT3f18kvuS3LprTSf5ye2vX5/kqdWNCACwvpbE1pVJntxxvLl9205/kOQ9VbWZ5GSS9+/1QFV1rKpOVdWpM2fOnMe4AADrZUls1R639a7j25Pc292Hk9yS5ItV9aLH7u7j3b3R3RuHDh0692kBANbMktjaTHLVjuPDefFlwjuS3J8k3f2vSV6T5IpVDAgAsM6WxNbDSY5U1bVVdVm2ngB/YteabyR5Z5JU1S9kK7ZcJwQAXvH2ja3ufiHJnUkeSPL1bL3q8NGquruqjm4v+1CS91XVvyf5cpL3dvfuS40AAK84ly5Z1N0ns/XE9523fXzH148ledtqRwMAWH/eQR4AYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBg0KLYqqqbqurxqjpdVXe9xJrfqKrHqurRqvrSascEAFhPl+63oKouSXJPkl9Nspnk4ao60d2P7VhzJMlHkrytu5+pqp+ZGhgAYJ0sObN1Y5LT3f1Edz+f5L4kt+5a874k93T3M0nS3U+vdkwAgPW0JLauTPLkjuPN7dt2emOSN1bVv1TVQ1V106oGBABYZ/teRkxSe9zWezzOkSTvSHI4yT9X1fXd/d0feaCqY0mOJcnVV199zsMCAKybJWe2NpNcteP4cJKn9ljzN939g+7+zySPZyu+fkR3H+/uje7eOHTo0PnODACwNpbE1sNJjlTVtVV1WZLbkpzYteavk/xKklTVFdm6rPjEKgcFAFhH+8ZWd7+Q5M4kDyT5epL7u/vRqrq7qo5uL3sgyber6rEkDyb5cHd/e2poAIB1Ud27n351MDY2NvrUqVMX5GcDAJyLqvpqd2+cz/d6B3kAgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQYtiq6puqqrHq+p0Vd11lnXvrqquqo3VjQgAsL72ja2quiTJPUluTnJdktur6ro91l2e5ANJvrLqIQEA1tWSM1s3Jjnd3U909/NJ7kty6x7rPpHkk0m+t8L5AADW2pLYujLJkzuON7dv+6GquiHJVd39tyucDQBg7S2Jrdrjtv7hnVWvSvLpJB/a94GqjlXVqao6debMmeVTAgCsqSWxtZnkqh3Hh5M8teP48iTXJ/nHqvqvJG9NcmKvJ8l39/Hu3ujujUOHDp3/1AAAa2JJbD2c5EhVXVtVlyW5LcmJ/7+zu5/t7iu6+5ruvibJQ0mOdvepkYkBANbIvrHV3S8kuTPJA0m+nuT+7n60qu6uqqPTAwIArLNLlyzq7pNJTu667eMvsfYdP/5YAAAvD95BHgBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGCS2AAAGiS0AgEFiCwBgkNgCABgktgAABoktAIBBYgsAYJDYAgAYJLYAAAaJLQCAQWILAGCQ2AIAGLQotqrqpqp6vKpOV9Vde9z/wap6rKoeqaq/r6qfXf2oAADrZ9/YqqpLktyT5OYk1yW5vaqu27Xsa0k2uvvNSf4qySdXPSgAwDpacmbrxiSnu/uJ7n4+yX1Jbt25oLsf7O7ntg8fSnJ4tWMCAKynJbF1ZZIndxxvbt/2Uu5I8nd73VFVx6rqVFWdOnPmzPIpAQDW1JLYqj1u6z0XVr0nyUaST+11f3cf7+6N7t44dOjQ8ikBANbUpQvWbCa5asfx4SRP7V5UVe9K8tEkb+/u769mPACA9bbkzNbDSY5U1bVVdVmS25Kc2Lmgqm5I8idJjnb306sfEwBgPe0bW939QpI7kzyQ5OtJ7u/uR6vq7qo6ur3sU0lel+Qvq+rfqurESzwcAMArypLLiOnuk0lO7rrt4zu+fteK5wIAeFnwDvIAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIPEFgDAILEFADBIbAEADBJbAACDxBYAwCCxBQAwSGwBAAwSWwAAgxbFVlXdVFWPV9Xpqrprj/t/oqr+Yvv+r1TVNaseFABgHe0bW1V1SZJ7ktyc5Lokt1fVdbuW3ZHkme7+uSSfTvKHqx4UAGAdLTmzdWOS0939RHc/n+S+JLfuWnNrkj/f/vqvkryzqmp1YwIArKclsXVlkid3HG9u37bnmu5+IcmzSX56FQMCAKyzSxes2esMVZ/HmlTVsSTHtg+/X1X/seDnc3G6Ism3LvQQnBd7t97s3/qyd+vt58/3G5fE1maSq3YcH07y1Eus2ayqS5O8Psl3dj9Qdx9PcjxJqupUd2+cz9BcePZvfdm79Wb/1pe9W29Vdep8v3fJZcSHkxypqmur6rIktyU5sWvNiSS/tf31u5P8Q3e/6MwWAMArzb5ntrr7haq6M8kDSS5J8vnufrSq7k5yqrtPJPmzJF+sqtPZOqN12+TQAADrYsllxHT3ySQnd9328R1ffy/Jr5/jzz5+juu5uNi/9WXv1pv9W1/2br2d9/6Vq30AAHN8XA8AwKDx2PJRP+trwd59sKoeq6pHqurvq+pnL8Sc7G2//dux7t1V1VXlVVIXkSX7V1W/sf07+GhVfemgZ2RvC/52Xl1VD1bV17b/ft5yIebkxarq81X19Eu9NVVt+cz23j5SVW9Z8rijseWjftbXwr37WpKN7n5ztj454JMHOyUvZeH+paouT/KBJF852Ak5myX7V1VHknwkydu6+xeT/O6BD8qLLPzd+1iS+7v7hmy9oOyzBzslZ3FvkpvOcv/NSY5s/zuW5HNLHnT6zJaP+llf++5ddz/Y3c9tHz6Urfdg4+Kw5HcvST6RrUj+3kEOx76W7N/7ktzT3c8kSXc/fcAzsrcle9dJfnL769fnxe9dyQXS3f+UPd4ndIdbk3yhtzyU5Keq6g37Pe50bPmon/W1ZO92uiPJ341OxLnYd/+q6oYkV3X33x7kYCyy5PfvjUneWFX/UlUPVdXZ/m+cg7Nk7/4gyXuqajNbr/R//8GMxgqc638bkyx864cfw8o+6ocDt3hfquo9STaSvH10Is7FWfevql6Vrcv27z2ogTgnS37/Ls3WpYx3ZOus8j9X1fXd/d3h2Ti7JXt3e5J7u/uPquqXs/U+ldd39//Oj8eP6byaZfrM1rl81E/O9lE/HLgle5eqeleSjyY52t3fP6DZ2N9++3d5kuuT/GNV/VeStyY54UnyF42lfzv/prt/0N3/meTxbMUXF9aSvbsjyf1J0t3/muQ12frcRC5+i/7buNt0bPmon/W1795tX4b6k2yFlueLXFzOun/d/Wx3X9Hd13T3Ndl6zt3R7j7vz/5ipZb87fzrJL+SJFV1RbYuKz5xoFOylyV7940k70ySqvqFbMXWmQOdkvN1Islvbr8q8a1Jnu3ub+73TaOXEX3Uz/pauHefSvK6JH+5/ZqGb3T30Qs2ND+0cP+4SC3cvweS/FpVPZbkf5J8uLu/feGmJlm8dx9K8qdV9XvZugT1XicZLg5V9eVsXZq/Yvs5db+f5NVJ0t1/nK3n2N2S5HSS55L89qLHtb8AAHO8gzwAwCCxBQAwSGwBAAwSWwAAg8QWAMAgsQUAMEhsAQAMElsAAIP+D4IQvstYe8a9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title('')\n",
    "plt.plot(err, 'r')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVn2uz5imSUt"
   },
   "source": [
    "### 5) Obtener las matrices $A$ y $\\Pi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GiBAYj7mSUu"
   },
   "outputs": [],
   "source": [
    "# Para cada palabra del alfabeto, predecir el vector de probabilidades\n",
    "# y agruparlos por columna para hacer la matriz A\n",
    "\n",
    "# A = []\n",
    "\n",
    "# for wj in Sigma[:-2]:\n",
    "#     aj = predict(word2oneHot[wj])\n",
    "#     A.append(list(aj))\n",
    "    \n",
    "# A = np.matrix(A).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCaWMrzEmSUx"
   },
   "outputs": [],
   "source": [
    "# El vector de inicio se obtiene al predecir la distribucion\n",
    "# para el simbolo <BOS>\n",
    "# Pi = predict(word2oneHot['<BOS>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "baCL2lS2mSUz"
   },
   "source": [
    "### 6) Calcular la propabilidad de las siguientes oraciones\n",
    "\n",
    "Se calcularan usando la propiedad de Markov que establece que:\n",
    "\n",
    "$p(x_1,...,x_n)=\\prod_{i=1}^{n}p(w_{i}|w_{i-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnysZ4akmSUz"
   },
   "source": [
    "1) Nos bañamos con agua caliente\n",
    "\n",
    "$p(caliente|agua)p(agua|con)p(con|banamos)p(banamos|nos)p(nos|BOS)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fa5gqXMSmSU1"
   },
   "outputs": [],
   "source": [
    "#s1 = 'Nos banamos con agua caliente'.split()\n",
    "# s1 = '<BOS> pascuala ordenaba las vacas'.split()\n",
    "# s1[1:] = [stemmer.stem(word.lower()) for word in s[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h12Aw7GfmSU3"
   },
   "outputs": [],
   "source": [
    "#j = word2number['las']\n",
    "#i = word2number['vacas']\n",
    "\n",
    "#A[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iy6Q8l5UmSU5"
   },
   "outputs": [],
   "source": [
    "#Pi[word2number['pues']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqgkKlGumSU7",
    "outputId": "09a8823d-d4e5-4116-b7a1-338b0dfd4688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(s) =  2.425589910422211e-19\n"
     ]
    }
   ],
   "source": [
    "# p = 1\n",
    "\n",
    "# for wi, wj in zip(s[:-1], s[1:]):\n",
    "#     if wi == '<BOS>':\n",
    "#         p *= Pi[word2number[wj]]\n",
    "#     else:\n",
    "#         i = word2number[wj]\n",
    "#         j = word2number[wi]\n",
    "#         p *= A[i,j]\n",
    "        \n",
    "# print('p(s) = ', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3BbKqxBJpLI"
   },
   "source": [
    "2) El animalito le olía la cabeza\n",
    "\n",
    "$p(cabeza|la)p(la|olía)p(olía|le)p(le|animalito)p(animalito|El)p(El|BOS)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jY2H8EG-KjRX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AUjRhJuKkZ5"
   },
   "source": [
    "3) Pascuala ordeñaba las vacas\n",
    "\n",
    "$p(vacas|las)p(las|ordeñaba)p(ordeñaba|Pascuala)p(Pascuala|BOS)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z44ZSwwQK7gM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yUSzh352uQBK"
   },
   "outputs": [],
   "source": [
    "jhyjk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMXWBr4kuVmv"
   },
   "source": [
    "jygyuguui\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practica2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
